{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "cpu\n",
      "<TTS.utils.manage.ModelManager object at 0x333b9b590>\n",
      " > tts_models/multilingual/multi-dataset/xtts_v2 is already downloaded.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/shivanshsrivastava/Desktop/digital-human/venv/lib/python3.11/site-packages/tqdm/auto.py:21: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " > Using model: xtts\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "from TTS.api import TTS\n",
    "import time\n",
    "\n",
    "# Get device\n",
    "device = \"cuda\" if torch.cuda.is_available() else \"cpu\"\n",
    "print(device)\n",
    "\n",
    "# List available ðŸ¸TTS models\n",
    "print(TTS().list_models())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " > tts_models/de/thorsten/tacotron2-DDC is already downloaded.\n",
      " > vocoder_models/de/thorsten/hifigan_v1 is already downloaded.\n",
      " > Using model: tacotron2\n",
      " > Setting up Audio Processor...\n",
      " | > sample_rate:22050\n",
      " | > resample:False\n",
      " | > num_mels:80\n",
      " | > log_func:np.log\n",
      " | > min_level_db:-100\n",
      " | > frame_shift_ms:None\n",
      " | > frame_length_ms:None\n",
      " | > ref_level_db:20\n",
      " | > fft_size:1024\n",
      " | > power:1.5\n",
      " | > preemphasis:0.0\n",
      " | > griffin_lim_iters:60\n",
      " | > signal_norm:False\n",
      " | > symmetric_norm:True\n",
      " | > mel_fmin:50.0\n",
      " | > mel_fmax:None\n",
      " | > pitch_fmin:0.0\n",
      " | > pitch_fmax:640.0\n",
      " | > spec_gain:1.0\n",
      " | > stft_pad_mode:reflect\n",
      " | > max_norm:4.0\n",
      " | > clip_norm:True\n",
      " | > do_trim_silence:True\n",
      " | > trim_db:60\n",
      " | > do_sound_norm:False\n",
      " | > do_amp_to_db_linear:True\n",
      " | > do_amp_to_db_mel:True\n",
      " | > do_rms_norm:False\n",
      " | > db_level:None\n",
      " | > stats_path:None\n",
      " | > base:2.718281828459045\n",
      " | > hop_length:256\n",
      " | > win_length:1024\n"
     ]
    },
    {
     "ename": "Exception",
     "evalue": " [!] No espeak backend found. Install espeak-ng or espeak to your system.",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mException\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[7], line 2\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[38;5;66;03m# Init TTS with the target model name\u001b[39;00m\n\u001b[0;32m----> 2\u001b[0m tts \u001b[38;5;241m=\u001b[39m \u001b[43mTTS\u001b[49m\u001b[43m(\u001b[49m\u001b[43mmodel_name\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mtts_models/de/thorsten/tacotron2-DDC\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mprogress_bar\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43;01mFalse\u001b[39;49;00m\u001b[43m)\u001b[49m\u001b[38;5;241m.\u001b[39mto(device)\n",
      "File \u001b[0;32m~/Desktop/digital-human/venv/lib/python3.11/site-packages/TTS/api.py:74\u001b[0m, in \u001b[0;36mTTS.__init__\u001b[0;34m(self, model_name, model_path, config_path, vocoder_path, vocoder_config_path, progress_bar, gpu)\u001b[0m\n\u001b[1;32m     72\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m model_name \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m \u001b[38;5;129;01mand\u001b[39;00m \u001b[38;5;28mlen\u001b[39m(model_name) \u001b[38;5;241m>\u001b[39m \u001b[38;5;241m0\u001b[39m:\n\u001b[1;32m     73\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mtts_models\u001b[39m\u001b[38;5;124m\"\u001b[39m \u001b[38;5;129;01min\u001b[39;00m model_name:\n\u001b[0;32m---> 74\u001b[0m         \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mload_tts_model_by_name\u001b[49m\u001b[43m(\u001b[49m\u001b[43mmodel_name\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mgpu\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m     75\u001b[0m     \u001b[38;5;28;01melif\u001b[39;00m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mvoice_conversion_models\u001b[39m\u001b[38;5;124m\"\u001b[39m \u001b[38;5;129;01min\u001b[39;00m model_name:\n\u001b[1;32m     76\u001b[0m         \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mload_vc_model_by_name(model_name, gpu)\n",
      "File \u001b[0;32m~/Desktop/digital-human/venv/lib/python3.11/site-packages/TTS/api.py:177\u001b[0m, in \u001b[0;36mTTS.load_tts_model_by_name\u001b[0;34m(self, model_name, gpu)\u001b[0m\n\u001b[1;32m    171\u001b[0m model_path, config_path, vocoder_path, vocoder_config_path, model_dir \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mdownload_model_by_name(\n\u001b[1;32m    172\u001b[0m     model_name\n\u001b[1;32m    173\u001b[0m )\n\u001b[1;32m    175\u001b[0m \u001b[38;5;66;03m# init synthesizer\u001b[39;00m\n\u001b[1;32m    176\u001b[0m \u001b[38;5;66;03m# None values are fetch from the model\u001b[39;00m\n\u001b[0;32m--> 177\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39msynthesizer \u001b[38;5;241m=\u001b[39m \u001b[43mSynthesizer\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m    178\u001b[0m \u001b[43m    \u001b[49m\u001b[43mtts_checkpoint\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mmodel_path\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    179\u001b[0m \u001b[43m    \u001b[49m\u001b[43mtts_config_path\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mconfig_path\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    180\u001b[0m \u001b[43m    \u001b[49m\u001b[43mtts_speakers_file\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43;01mNone\u001b[39;49;00m\u001b[43m,\u001b[49m\n\u001b[1;32m    181\u001b[0m \u001b[43m    \u001b[49m\u001b[43mtts_languages_file\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43;01mNone\u001b[39;49;00m\u001b[43m,\u001b[49m\n\u001b[1;32m    182\u001b[0m \u001b[43m    \u001b[49m\u001b[43mvocoder_checkpoint\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mvocoder_path\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    183\u001b[0m \u001b[43m    \u001b[49m\u001b[43mvocoder_config\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mvocoder_config_path\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    184\u001b[0m \u001b[43m    \u001b[49m\u001b[43mencoder_checkpoint\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43;01mNone\u001b[39;49;00m\u001b[43m,\u001b[49m\n\u001b[1;32m    185\u001b[0m \u001b[43m    \u001b[49m\u001b[43mencoder_config\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43;01mNone\u001b[39;49;00m\u001b[43m,\u001b[49m\n\u001b[1;32m    186\u001b[0m \u001b[43m    \u001b[49m\u001b[43mmodel_dir\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mmodel_dir\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    187\u001b[0m \u001b[43m    \u001b[49m\u001b[43muse_cuda\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mgpu\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    188\u001b[0m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/Desktop/digital-human/venv/lib/python3.11/site-packages/TTS/utils/synthesizer.py:93\u001b[0m, in \u001b[0;36mSynthesizer.__init__\u001b[0;34m(self, tts_checkpoint, tts_config_path, tts_speakers_file, tts_languages_file, vocoder_checkpoint, vocoder_config, encoder_checkpoint, encoder_config, vc_checkpoint, vc_config, model_dir, voice_dir, use_cuda)\u001b[0m\n\u001b[1;32m     90\u001b[0m     \u001b[38;5;28;01massert\u001b[39;00m torch\u001b[38;5;241m.\u001b[39mcuda\u001b[38;5;241m.\u001b[39mis_available(), \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mCUDA is not availabe on this machine.\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m     92\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m tts_checkpoint:\n\u001b[0;32m---> 93\u001b[0m     \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_load_tts\u001b[49m\u001b[43m(\u001b[49m\u001b[43mtts_checkpoint\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mtts_config_path\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43muse_cuda\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m     94\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39moutput_sample_rate \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mtts_config\u001b[38;5;241m.\u001b[39maudio[\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124msample_rate\u001b[39m\u001b[38;5;124m\"\u001b[39m]\n\u001b[1;32m     96\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m vocoder_checkpoint:\n",
      "File \u001b[0;32m~/Desktop/digital-human/venv/lib/python3.11/site-packages/TTS/utils/synthesizer.py:187\u001b[0m, in \u001b[0;36mSynthesizer._load_tts\u001b[0;34m(self, tts_checkpoint, tts_config_path, use_cuda)\u001b[0m\n\u001b[1;32m    184\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mtts_config[\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124muse_phonemes\u001b[39m\u001b[38;5;124m\"\u001b[39m] \u001b[38;5;129;01mand\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mtts_config[\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mphonemizer\u001b[39m\u001b[38;5;124m\"\u001b[39m] \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[1;32m    185\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mValueError\u001b[39;00m(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mPhonemizer is not defined in the TTS config.\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n\u001b[0;32m--> 187\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mtts_model \u001b[38;5;241m=\u001b[39m \u001b[43msetup_tts_model\u001b[49m\u001b[43m(\u001b[49m\u001b[43mconfig\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mtts_config\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    189\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mencoder_checkpoint:\n\u001b[1;32m    190\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_set_speaker_encoder_paths_from_tts_config()\n",
      "File \u001b[0;32m~/Desktop/digital-human/venv/lib/python3.11/site-packages/TTS/tts/models/__init__.py:13\u001b[0m, in \u001b[0;36msetup_model\u001b[0;34m(config, samples)\u001b[0m\n\u001b[1;32m     11\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m     12\u001b[0m     MyModel \u001b[38;5;241m=\u001b[39m find_module(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mTTS.tts.models\u001b[39m\u001b[38;5;124m\"\u001b[39m, config\u001b[38;5;241m.\u001b[39mmodel\u001b[38;5;241m.\u001b[39mlower())\n\u001b[0;32m---> 13\u001b[0m model \u001b[38;5;241m=\u001b[39m \u001b[43mMyModel\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43minit_from_config\u001b[49m\u001b[43m(\u001b[49m\u001b[43mconfig\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mconfig\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43msamples\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43msamples\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m     14\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m model\n",
      "File \u001b[0;32m~/Desktop/digital-human/venv/lib/python3.11/site-packages/TTS/tts/models/tacotron2.py:431\u001b[0m, in \u001b[0;36mTacotron2.init_from_config\u001b[0;34m(config, samples)\u001b[0m\n\u001b[1;32m    428\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mTTS\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mutils\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01maudio\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m AudioProcessor\n\u001b[1;32m    430\u001b[0m ap \u001b[38;5;241m=\u001b[39m AudioProcessor\u001b[38;5;241m.\u001b[39minit_from_config(config)\n\u001b[0;32m--> 431\u001b[0m tokenizer, new_config \u001b[38;5;241m=\u001b[39m \u001b[43mTTSTokenizer\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43minit_from_config\u001b[49m\u001b[43m(\u001b[49m\u001b[43mconfig\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    432\u001b[0m speaker_manager \u001b[38;5;241m=\u001b[39m SpeakerManager\u001b[38;5;241m.\u001b[39minit_from_config(new_config, samples)\n\u001b[1;32m    433\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m Tacotron2(new_config, ap, tokenizer, speaker_manager)\n",
      "File \u001b[0;32m~/Desktop/digital-human/venv/lib/python3.11/site-packages/TTS/tts/utils/text/tokenizer.py:198\u001b[0m, in \u001b[0;36mTTSTokenizer.init_from_config\u001b[0;34m(config, characters)\u001b[0m\n\u001b[1;32m    196\u001b[0m phonemizer_kwargs \u001b[38;5;241m=\u001b[39m {\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mlanguage\u001b[39m\u001b[38;5;124m\"\u001b[39m: config\u001b[38;5;241m.\u001b[39mphoneme_language}\n\u001b[1;32m    197\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mphonemizer\u001b[39m\u001b[38;5;124m\"\u001b[39m \u001b[38;5;129;01min\u001b[39;00m config \u001b[38;5;129;01mand\u001b[39;00m config\u001b[38;5;241m.\u001b[39mphonemizer:\n\u001b[0;32m--> 198\u001b[0m     phonemizer \u001b[38;5;241m=\u001b[39m \u001b[43mget_phonemizer_by_name\u001b[49m\u001b[43m(\u001b[49m\u001b[43mconfig\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mphonemizer\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mphonemizer_kwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    199\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m    200\u001b[0m     \u001b[38;5;28;01mtry\u001b[39;00m:\n",
      "File \u001b[0;32m~/Desktop/digital-human/venv/lib/python3.11/site-packages/TTS/tts/utils/text/phonemizers/__init__.py:60\u001b[0m, in \u001b[0;36mget_phonemizer_by_name\u001b[0;34m(name, **kwargs)\u001b[0m\n\u001b[1;32m     50\u001b[0m \u001b[38;5;250m\u001b[39m\u001b[38;5;124;03m\"\"\"Initiate a phonemizer by name\u001b[39;00m\n\u001b[1;32m     51\u001b[0m \n\u001b[1;32m     52\u001b[0m \u001b[38;5;124;03mArgs:\u001b[39;00m\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m     57\u001b[0m \u001b[38;5;124;03m        Extra keyword arguments that should be passed to the phonemizer.\u001b[39;00m\n\u001b[1;32m     58\u001b[0m \u001b[38;5;124;03m\"\"\"\u001b[39;00m\n\u001b[1;32m     59\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m name \u001b[38;5;241m==\u001b[39m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mespeak\u001b[39m\u001b[38;5;124m\"\u001b[39m:\n\u001b[0;32m---> 60\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mESpeak\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m     61\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m name \u001b[38;5;241m==\u001b[39m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mgruut\u001b[39m\u001b[38;5;124m\"\u001b[39m:\n\u001b[1;32m     62\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m Gruut(\u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)\n",
      "File \u001b[0;32m~/Desktop/digital-human/venv/lib/python3.11/site-packages/TTS/tts/utils/text/phonemizers/espeak_wrapper.py:114\u001b[0m, in \u001b[0;36mESpeak.__init__\u001b[0;34m(self, language, backend, punctuations, keep_puncs)\u001b[0m\n\u001b[1;32m    112\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21m__init__\u001b[39m(\u001b[38;5;28mself\u001b[39m, language: \u001b[38;5;28mstr\u001b[39m, backend\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mNone\u001b[39;00m, punctuations\u001b[38;5;241m=\u001b[39mPunctuation\u001b[38;5;241m.\u001b[39mdefault_puncs(), keep_puncs\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mTrue\u001b[39;00m):\n\u001b[1;32m    113\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_ESPEAK_LIB \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[0;32m--> 114\u001b[0m         \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mException\u001b[39;00m(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m [!] No espeak backend found. Install espeak-ng or espeak to your system.\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n\u001b[1;32m    115\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mbackend \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_ESPEAK_LIB\n\u001b[1;32m    117\u001b[0m     \u001b[38;5;66;03m# band-aid for backwards compatibility\u001b[39;00m\n",
      "\u001b[0;31mException\u001b[0m:  [!] No espeak backend found. Install espeak-ng or espeak to your system."
     ]
    }
   ],
   "source": [
    "# Init TTS with the target model name\n",
    "tts = TTS(model_name=\"tts_models/de/thorsten/tacotron2-DDC\", progress_bar=False).to(device)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "ename": "ValueError",
     "evalue": "Model is multi-speaker but no `speaker` is provided.",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[8], line 2\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[38;5;66;03m# Run TTS\u001b[39;00m\n\u001b[0;32m----> 2\u001b[0m \u001b[43mtts\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mtts_to_file\u001b[49m\u001b[43m(\u001b[49m\u001b[43mtext\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mIch bin eine Testnachricht.\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mfile_path\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43moutput.wav\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/Desktop/digital-human/venv/lib/python3.11/site-packages/TTS/api.py:332\u001b[0m, in \u001b[0;36mTTS.tts_to_file\u001b[0;34m(self, text, speaker, language, speaker_wav, emotion, speed, pipe_out, file_path, split_sentences, **kwargs)\u001b[0m\n\u001b[1;32m    290\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mtts_to_file\u001b[39m(\n\u001b[1;32m    291\u001b[0m     \u001b[38;5;28mself\u001b[39m,\n\u001b[1;32m    292\u001b[0m     text: \u001b[38;5;28mstr\u001b[39m,\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m    301\u001b[0m     \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs,\n\u001b[1;32m    302\u001b[0m ):\n\u001b[1;32m    303\u001b[0m \u001b[38;5;250m    \u001b[39m\u001b[38;5;124;03m\"\"\"Convert text to speech.\u001b[39;00m\n\u001b[1;32m    304\u001b[0m \n\u001b[1;32m    305\u001b[0m \u001b[38;5;124;03m    Args:\u001b[39;00m\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m    330\u001b[0m \u001b[38;5;124;03m            Additional arguments for the model.\u001b[39;00m\n\u001b[1;32m    331\u001b[0m \u001b[38;5;124;03m    \"\"\"\u001b[39;00m\n\u001b[0;32m--> 332\u001b[0m     \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_check_arguments\u001b[49m\u001b[43m(\u001b[49m\u001b[43mspeaker\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mspeaker\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mlanguage\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mlanguage\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mspeaker_wav\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mspeaker_wav\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    334\u001b[0m     wav \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mtts(\n\u001b[1;32m    335\u001b[0m         text\u001b[38;5;241m=\u001b[39mtext,\n\u001b[1;32m    336\u001b[0m         speaker\u001b[38;5;241m=\u001b[39mspeaker,\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m    340\u001b[0m         \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs,\n\u001b[1;32m    341\u001b[0m     )\n\u001b[1;32m    342\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39msynthesizer\u001b[38;5;241m.\u001b[39msave_wav(wav\u001b[38;5;241m=\u001b[39mwav, path\u001b[38;5;241m=\u001b[39mfile_path, pipe_out\u001b[38;5;241m=\u001b[39mpipe_out)\n",
      "File \u001b[0;32m~/Desktop/digital-human/venv/lib/python3.11/site-packages/TTS/api.py:227\u001b[0m, in \u001b[0;36mTTS._check_arguments\u001b[0;34m(self, speaker, language, speaker_wav, emotion, speed, **kwargs)\u001b[0m\n\u001b[1;32m    225\u001b[0m \u001b[38;5;66;03m# check for the coqui tts models\u001b[39;00m\n\u001b[1;32m    226\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mis_multi_speaker \u001b[38;5;129;01mand\u001b[39;00m (speaker \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m \u001b[38;5;129;01mand\u001b[39;00m speaker_wav \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m):\n\u001b[0;32m--> 227\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mValueError\u001b[39;00m(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mModel is multi-speaker but no `speaker` is provided.\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n\u001b[1;32m    228\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mis_multi_lingual \u001b[38;5;129;01mand\u001b[39;00m language \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[1;32m    229\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mValueError\u001b[39;00m(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mModel is multi-lingual but no `language` is provided.\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n",
      "\u001b[0;31mValueError\u001b[0m: Model is multi-speaker but no `speaker` is provided."
     ]
    }
   ],
   "source": [
    "# Run TTS\n",
    "tts.tts_to_file(text=\"Ich bin eine Testnachricht.\", file_path='output.wav')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
